{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8lnw5-Bb8hZI"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from collections import defaultdict\n",
        "from typing import List, Dict, Tuple\n",
        "\n",
        "class NGramModel:\n",
        "    def __init__(self, n: int = 3, is_char_level: bool = False):\n",
        "        \"\"\"\n",
        "        Initialize the n-gram model.\n",
        "\n",
        "        Args:\n",
        "            n: The 'n' in n-gram (e.g., 2 for bigram, 3 for trigram)\n",
        "            is_char_level: If True, works at character level; if False, at word level\n",
        "        \"\"\"\n",
        "        self.n = n\n",
        "        self.is_char_level = is_char_level\n",
        "        self.ngram_counts = defaultdict(int)\n",
        "        self.context_counts = defaultdict(int)\n",
        "        self.vocab = set()\n",
        "\n",
        "    def preprocess(self, text: str) -> List[str]:\n",
        "        \"\"\"Convert text to tokens (either words or characters).\"\"\"\n",
        "        if self.is_char_level:\n",
        "            return list(text)\n",
        "        else:\n",
        "            # Simple word tokenization (split on whitespace)\n",
        "            return text.split()\n",
        "\n",
        "    def train(self, text: str) -> None:\n",
        "        \"\"\"Train the model on the given text.\"\"\"\n",
        "        tokens = self.preprocess(text)\n",
        "        self.vocab.update(tokens)\n",
        "\n",
        "        # Pad the beginning with special tokens to handle start of sequence\n",
        "        padded_tokens = ['<START>'] * (self.n - 1) + tokens + ['<END>']\n",
        "\n",
        "        # Count n-grams and their contexts\n",
        "        for i in range(len(padded_tokens) - self.n + 1):\n",
        "            ngram = tuple(padded_tokens[i:i + self.n])\n",
        "            context = ngram[:-1]\n",
        "            self.ngram_counts[ngram] += 1\n",
        "            self.context_counts[context] += 1\n",
        "\n",
        "    def generate(self, max_length: int = 50) -> str:\n",
        "        \"\"\"Generate text from the model.\"\"\"\n",
        "        result = ['<START>'] * (self.n - 1)\n",
        "\n",
        "        for _ in range(max_length):\n",
        "            context = tuple(result[-(self.n - 1):])\n",
        "\n",
        "            # If context is unseen, return what we have\n",
        "            if context not in self.context_counts:\n",
        "                break\n",
        "\n",
        "            # Get possible next tokens and their probabilities\n",
        "            possible_ngrams = [ngram for ngram in self.ngram_counts\n",
        "                             if ngram[:-1] == context]\n",
        "            probabilities = [self.ngram_counts[ngram] / self.context_counts[context]\n",
        "                            for ngram in possible_ngrams]\n",
        "            next_ngram = random.choices(possible_ngrams, weights=probabilities)[0]\n",
        "            next_token = next_ngram[-1]\n",
        "\n",
        "            # Stop if we hit the end token\n",
        "            if next_token == '<END>':\n",
        "                break\n",
        "\n",
        "            result.append(next_token)\n",
        "\n",
        "        # Remove start tokens and convert to string\n",
        "        generated = result[self.n - 1:]\n",
        "        if self.is_char_level:\n",
        "            return ''.join(generated)\n",
        "        else:\n",
        "            return ' '.join(generated)\n",
        "\n",
        "    def probability(self, sequence: str) -> float:\n",
        "        \"\"\"Calculate the probability of a sequence under the model.\"\"\"\n",
        "        tokens = self.preprocess(sequence)\n",
        "        padded_tokens = ['<START>'] * (self.n - 1) + tokens + ['<END>']\n",
        "        total_prob = 1.0\n",
        "\n",
        "        for i in range(len(padded_tokens) - self.n + 1):\n",
        "            ngram = tuple(padded_tokens[i:i + self.n])\n",
        "            context = ngram[:-1]\n",
        "\n",
        "            if context in self.context_counts:\n",
        "                prob = self.ngram_counts.get(ngram, 0) / self.context_counts[context]\n",
        "                total_prob *= prob\n",
        "            else:\n",
        "                return 0.0  # Unseen context\n",
        "\n",
        "        return total_prob"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # Sample training text\n",
        "    training_text = \"\"\"\n",
        "    This is a simple example text for training our n-gram model.\n",
        "    The model will learn the probabilities of word sequences.\n",
        "    It's not very sophisticated but it demonstrates the concept.\n",
        "    \"\"\"\n",
        "\n",
        "    # Word-level trigram model\n",
        "    print(\"Training word-level trigram model...\")\n",
        "    word_model = NGramModel(n=3, is_char_level=False)\n",
        "    word_model.train(training_text)\n",
        "\n",
        "    print(\"\\nGenerated text (word level):\")\n",
        "    print(word_model.generate())\n",
        "\n",
        "    # Character-level bigram model\n",
        "    print(\"\\nTraining character-level bigram model...\")\n",
        "    char_model = NGramModel(n=2, is_char_level=True)\n",
        "    char_model.train(training_text)\n",
        "\n",
        "    print(\"\\nGenerated text (character level):\")\n",
        "    print(char_model.generate(100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzPY_5mT9h3i",
        "outputId": "112d3c2b-99fe-4a6f-9e22-e1b48661ce46"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training word-level trigram model...\n",
            "\n",
            "Generated text (word level):\n",
            "This is a simple example text for training our n-gram model. The model will learn the probabilities of word sequences. It's not very sophisticated but it demonstrates the concept.\n",
            "\n",
            "Training character-level bigram model...\n",
            "\n",
            "Generated text (character level):\n",
            "\n",
            "Therampl t t imongrabaramorary t mobist witer de mouelelerouroueabatheamplequt f s l lepllisthinoro\n",
            "\n",
            "Probability of 'This is a simple': 0.000000\n"
          ]
        }
      ]
    }
  ]
}