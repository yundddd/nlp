{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lnw5-Bb8hZI"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from collections import defaultdict\n",
        "from typing import List, Dict, Tuple\n",
        "\n",
        "class NGramModel:\n",
        "    def __init__(self, n: int = 3, is_char_level: bool = False):\n",
        "        \"\"\"\n",
        "        Initialize the n-gram model.\n",
        "\n",
        "        Args:\n",
        "            n: The 'n' in n-gram (e.g., 2 for bigram, 3 for trigram)\n",
        "            is_char_level: If True, works at character level; if False, at word level\n",
        "        \"\"\"\n",
        "        self.n = n\n",
        "\n",
        "        # Character level generation outputs one character at a time.\n",
        "        # Word level outputs one word at a time.\n",
        "        # Which one is better?\n",
        "        self.is_char_level = is_char_level\n",
        "\n",
        "        # Counts frequency of each ngram\n",
        "        # \"I love to eat\" -> 1\n",
        "        # \"I love to play\" -> 2\n",
        "        self.ngram_counts = defaultdict(int)\n",
        "\n",
        "        # \"I love to\" -> 3\n",
        "        self.context_counts = defaultdict(int)\n",
        "\n",
        "        # unique vocabulary\n",
        "        self.vocab = set()\n",
        "\n",
        "    def preprocess(self, text: str) -> List[str]:\n",
        "        \"\"\"Convert text to tokens (either words or characters).\"\"\"\n",
        "        if self.is_char_level:\n",
        "            return list(text)\n",
        "        else:\n",
        "            # Simple word tokenization (split on whitespace)\n",
        "            return text.split()\n",
        "\n",
        "    def train(self, text: str) -> None:\n",
        "        \"\"\"Train the model on the given text.\"\"\"\n",
        "        tokens = self.preprocess(text)\n",
        "        self.vocab.update(tokens)\n",
        "\n",
        "        # Pad the beginning with special tokens to handle start of sequence\n",
        "        # Why do we need to pad multiple start token?\n",
        "        # To provide correct starting conext.\n",
        "        #     2-gram: <START> I love to eat <END>\n",
        "        #     3-gram: <START> <START> I love to eat <END>\n",
        "        padded_tokens = ['<START>'] * (self.n - 1) + tokens + ['<END>']\n",
        "\n",
        "        # Count n-grams and their contexts:\n",
        "        # <START> I love to eat <END>\n",
        "        # ngram:\n",
        "        #   <START> I\n",
        "        #   I love\n",
        "        #   love to\n",
        "        #   to eat\n",
        "        #   eat <END>\n",
        "        # context:\n",
        "        #   <START>\n",
        "        #   I\n",
        "        #   love\n",
        "        #   to\n",
        "        #   eat\n",
        "        for i in range(len(padded_tokens) - self.n + 1):\n",
        "            ngram = tuple(padded_tokens[i:i + self.n])\n",
        "            context = ngram[:-1]\n",
        "            self.ngram_counts[ngram] += 1\n",
        "            self.context_counts[context] += 1\n",
        "\n",
        "    def generate(self, max_length: int = 50) -> str:\n",
        "        \"\"\"Generate text from the model.\"\"\"\n",
        "        result = ['<START>'] * (self.n - 1)\n",
        "\n",
        "        for _ in range(max_length):\n",
        "            context = tuple(result[-(self.n - 1):])\n",
        "\n",
        "            # If context is unseen, return what we have\n",
        "            if context not in self.context_counts:\n",
        "                break\n",
        "\n",
        "            # Get possible next tokens and their probabilities\n",
        "            #  \"I love to eat pizza\"\n",
        "            #  \"I love to play violin\"\n",
        "            #  \"I love to play soccer\"\n",
        "            # Will generate\n",
        "            #  \"I love to play\"\n",
        "            possible_ngrams = [ngram for ngram in self.ngram_counts\n",
        "                             if ngram[:-1] == context]\n",
        "            probabilities = [self.ngram_counts[ngram] / self.context_counts[context]\n",
        "                            for ngram in possible_ngrams]\n",
        "            next_ngram = random.choices(possible_ngrams, weights=probabilities)[0]\n",
        "            next_token = next_ngram[-1]\n",
        "\n",
        "            # Stop if we hit the end token\n",
        "            if next_token == '<END>':\n",
        "                break\n",
        "\n",
        "            result.append(next_token)\n",
        "\n",
        "        # Remove start tokens and convert to string\n",
        "        generated = result[self.n - 1:]\n",
        "        if self.is_char_level:\n",
        "            return ''.join(generated)\n",
        "        else:\n",
        "            return ' '.join(generated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzPY_5mT9h3i",
        "outputId": "112d3c2b-99fe-4a6f-9e22-e1b48661ce46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training word-level trigram model...\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'NGramModel' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Word-level trigram model\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining word-level trigram model...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m word_model = \u001b[43mNGramModel\u001b[49m(n=\u001b[32m2\u001b[39m, is_char_level=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     10\u001b[39m word_model.train(training_text)\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mGenerated text (word level):\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mNameError\u001b[39m: name 'NGramModel' is not defined"
          ]
        }
      ],
      "source": [
        "# Sample training text\n",
        "training_text = \"\"\"\n",
        "This is a simple example text for training our n-gram model.\n",
        "The model will learn the probabilities of word sequences.\n",
        "It's not very sophisticated but it demonstrates the concept.\n",
        "\"\"\"\n",
        "# Word-level trigram model\n",
        "print(\"Training word-level trigram model...\")\n",
        "word_model = NGramModel(n=2, is_char_level=False)\n",
        "word_model.train(training_text)\n",
        "\n",
        "print(\"\\nGenerated text (word level):\")\n",
        "print(word_model.generate())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training character-level bigram model...\n",
            "\n",
            "Generated text (character level):\n",
            "\n",
            "The ves ve oncotes atepleque thicatrd biexamote mprarabut wimoraicesobis bainonces de t.\n",
            "Thes wit n\n"
          ]
        }
      ],
      "source": [
        "# Character-level bigram model\n",
        "print(\"\\nTraining character-level bigram model...\")\n",
        "\n",
        "char_model = NGramModel(n=2, is_char_level=True)\n",
        "char_model.train(training_text)\n",
        "print(\"\\nGenerated text (character level):\")\n",
        "print(char_model.generate(100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training word-level  model...\n",
            "\n",
            "Generated text (word level):\n",
            "A crew of Athens calls. Their wonted sight. When thou hast by break not; I am to choose love is your royal walks, your father's ground Sleep give me ere I swore. HELENA A Midsummer Night's Dream by tomorrow midnight solemnly Dance in dark uneven way, And yonder shines Aurora's\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "def download_to_string(url: str) -> str:\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Raise an error for bad status codes (4xx/5xx)\n",
        "        return response.text\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error downloading from {url}: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/cobanov/shakespeare-dataset/refs/heads/main/text/a-midsummer-nights-dream_TXT_FolgerShakespeare.txt\"\n",
        "content = download_to_string(url)\n",
        "\n",
        "print(\"Training word-level  model...\")\n",
        "word_model = NGramModel(n=2, is_char_level=False)\n",
        "word_model.train(content)\n",
        "\n",
        "print(\"\\nGenerated text (word level):\")\n",
        "print(word_model.generate())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
